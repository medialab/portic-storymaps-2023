{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "555245eb-8076-4c87-b97f-4e8f9c161d7f",
   "metadata": {},
   "source": [
    "# Cheatsheet pour le datasprint 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde10e24-be14-49b0-8b76-23785da7d9bc",
   "metadata": {},
   "source": [
    "## Toflit18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7669324-eb52-4263-b51f-ea2e5effe798",
   "metadata": {},
   "source": [
    "## Récupérer tous les flux avec Marseille comme direction des fermes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd7e06-c3cf-4111-9b7e-39136524526b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "flows = []\n",
    "with open('../data/toflit18_all_flows.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row['customs_region'] == 'Marseille':\n",
    "            flows.append(row)\n",
    "print(len(flows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37998ab2-58c8-4d26-8075-86956ad00be2",
   "metadata": {},
   "source": [
    "## Récupérer tous les flux d'import avec Marseille comme direction des fermes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30400a65-6bfb-4886-b3c8-a59555a1e0bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "flows = []\n",
    "with open('../data/toflit18_all_flows.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if \\\n",
    "                row['customs_region'] == 'Marseille' \\\n",
    "            and row['export_import'] == 'Imports' \\\n",
    "            :\n",
    "            flows.append(row)\n",
    "print(len(flows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b54c9-809a-407f-a1d7-fcad43bfef2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Récupérer tous les flux d'import avec Marseille comme direction des fermes en 1789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fa91a-f9c3-437b-8080-c574edc47cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "flows = []\n",
    "with open('../data/toflit18_all_flows.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if \\\n",
    "                row['customs_region'] == 'Marseille' \\\n",
    "            and row['export_import'] == 'Imports' \\\n",
    "            and row['year'] == '1789'\\\n",
    "            :\n",
    "            flows.append(row)\n",
    "print(len(flows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941a76b-b151-4b3e-8587-cad9b52eaf13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Récupérer tous les flux d'import avec Marseille comme direction des fermes en 1789, seulement avec les sources qui contiennent produits et partenaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6fd450-30be-40ba-806e-50d31ed069ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "flows = []\n",
    "with open('../data/toflit18_all_flows.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if \\\n",
    "                row['customs_region'] == 'Marseille' \\\n",
    "            and row['export_import'] == 'Imports' \\\n",
    "            and row['year'] == '1789' \\\n",
    "            and row['best_guess_region_prodxpart'] == '1' \\\n",
    "        :\n",
    "            flows.append(row)\n",
    "print(len(flows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a695f52d-0ffb-4e8b-a86e-988be6ccdde6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Récupérer tous les flux d'export vers Marseille comme partenaire en 1789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078a5b90-0387-4b5b-bc8a-40ca5d35cde3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "flows = []\n",
    "with open('../data/toflit18_all_flows.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if \\\n",
    "                row['partner_simplification'] == 'Marseille' \\\n",
    "            and row['export_import'] == 'Exports' \\\n",
    "            and row['year'] == '1789' \\\n",
    "            :\n",
    "            flows.append(row)\n",
    "print(len(flows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b89b8d-f51f-4a04-8f94-fccbccc38abc",
   "metadata": {},
   "source": [
    "## Navigo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eb0ccb-6710-4e12-a49c-f93f564099e1",
   "metadata": {},
   "source": [
    "### Récupérer tous les pointcalls concernant Marseille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5f7b4-422b-42d5-95ad-cc6aeacf9562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "pointcalls = []\n",
    "with open('../data/navigo_all_pointcalls.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row['toponyme_fr'] == 'Marseille':\n",
    "            pointcalls.append(row)\n",
    "print(len(pointcalls))\n",
    "\n",
    "# import json\n",
    "# print(json.dumps(pointcalls[0], sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ad66f-e7bf-4018-ba0d-3d954fa1027f",
   "metadata": {},
   "source": [
    "### Récupérer tous les pointcalls concernant Marseille en 1789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59f23d-f770-4b5f-ad54-1fd6c8d702bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "pointcalls = []\n",
    "with open('../data/navigo_all_pointcalls.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row['toponyme_fr'] == 'Marseille' \\\n",
    "           and row['date_fixed'].split('-')[0] == '1789':\n",
    "            pointcalls.append(row)\n",
    "\n",
    "print(len(pointcalls))\n",
    "# import json\n",
    "# print(json.dumps(pointcalls[0], sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86296977-b43b-4ade-b069-6ea22f503628",
   "metadata": {},
   "source": [
    "### Récupérer tous les pointcalls concernant une **arrivée** à Marseille en 1789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d2a836-0058-4f41-84f7-ae3724e2f157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "pointcalls = []\n",
    "with open('../data/navigo_all_pointcalls.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if \\\n",
    "                row['toponyme_fr'] == 'Marseille' \\\n",
    "            and row['date_fixed'].split('-')[0] == '1789' \\\n",
    "            and row['pointcall_action'] == 'In'\\\n",
    "            :\n",
    "            pointcalls.append(row)\n",
    "\n",
    "print(len(pointcalls))\n",
    "# import json\n",
    "# print(json.dumps(pointcalls[0], sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec6a9e1-5188-4b7d-911b-a477c8a97565",
   "metadata": {},
   "source": [
    "### Récupérer la distribution des ports d'attache de tous les navires à Marseille en 1789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fad504-46f1-4025-b99b-69be10f4dfdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "homeports = Counter()\n",
    "with open('../data/navigo_all_pointcalls.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if \\\n",
    "                row['toponyme_fr'] == 'Marseille' \\\n",
    "            and row['date_fixed'].split('-')[0] == '1789' \\\n",
    "            and row['pointcall_action'] == 'In' \\\n",
    "            :\n",
    "            homeport = row['homeport_toponyme_fr']\n",
    "            homeports.update({homeport: 1})\n",
    "            \n",
    "homeports_as_array = [{\"homeport\": homeport if homeport != '' else 'sans port d\\'attache déclaré', \"count\": count} for homeport, count in homeports.items()]\n",
    "for p in sorted(homeports_as_array, key=lambda d : -d['count']):\n",
    "    print(p['homeport'] + ' : ' + str(p['count']) + ' entrées')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b460cb9-c58b-4ed6-bf5a-3d8102c0f3a0",
   "metadata": {},
   "source": [
    "### Récupérer toutes les cargaisons entrées à Marseille en 1789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ef7e4-0bcf-4b2d-8d35-ccfd6a81191d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "import json\n",
    "import re\n",
    "\n",
    "def single_quote_double(single_quoted):\n",
    "  cList=list(single_quoted)\n",
    "  in_double=False;\n",
    "  in_single=False;\n",
    "  for i,c in enumerate(cList):\n",
    "      if c==\"'\":\n",
    "          if not in_double:\n",
    "              in_single = not in_single\n",
    "              cList[i]='\"'\n",
    "      elif c=='\"':\n",
    "          in_double = not in_double\n",
    "  double_quoted = \"\".join(cList)    \n",
    "  return double_quoted\n",
    "\n",
    "def parse_all_cargos_field(str):\n",
    "    all_cargos = []\n",
    "    input_cargos_fixed = single_quote_double(str or '[]').replace(\"'\", ' ')\n",
    "    # the following line works to solve issues but sometimes makes python run into an infinite loop\n",
    "    # python people help !\n",
    "    # input_cargos_fixed = re.sub(r'\\\".*(\\\").*(\\\")\\\",', '', input_cargos_fixed, 2)\n",
    "    \n",
    "    try:\n",
    "        all_cargos = json.loads(input_cargos_fixed)\n",
    "    except ValueError:\n",
    "        #print('===')\n",
    "        #print('Error with : ')\n",
    "        #print(str)\n",
    "        #print(input_cargos_fixed)\n",
    "        return []\n",
    "    return all_cargos\n",
    "\n",
    "cargos = []\n",
    "with open('../data/navigo_all_pointcalls.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for i, row in enumerate(reader):\n",
    "        if row['toponyme_fr'] == 'Marseille' \\\n",
    "           and row['date_fixed'].split('-')[0] == '1789':\n",
    "            all_cargos = parse_all_cargos_field(row['all_cargos'])\n",
    "            for cargo in all_cargos:\n",
    "                if \\\n",
    "                        'cargo_item_action' in cargo \\\n",
    "                    and cargo['cargo_item_action'] == 'In'\n",
    "                    \\:\n",
    "                    cargos.append(cargo)\n",
    "print(len(cargos))\n",
    "print(json.dumps(cargos[0], sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4580c-b588-4890-84b7-2f2b50beddb3",
   "metadata": {},
   "source": [
    "## Récupérer la liste des voyages déclarés à destination de Marseille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb05e43-5f91-4127-9ced-f23860db6167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "flows = []\n",
    "with open('../data/navigo_all_flows.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if \\\n",
    "                row['destination_fr'] == 'Marseille' \\\n",
    "            :\n",
    "            flows.append(dict(row))\n",
    "\n",
    "print(len(flows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c47c9-9c2a-4be0-a6c4-f56e2b9a3f2b",
   "metadata": {},
   "source": [
    "## Récupérer la liste des voyages déclarés à destination de Marseille et arrivés en 1789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc75d54-b3bd-4816-8d9d-001eee83aa9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "flows = []\n",
    "with open('../data/navigo_all_flows.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if \\\n",
    "                row['destination_fr'] == 'Marseille' \\\n",
    "            and row['indate_fixed'].split('-')[0] == '1789' \\\n",
    "            :\n",
    "            flows.append(dict(row))\n",
    "\n",
    "print(len(flows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07e087-af8a-474f-867b-8fcd505d60ca",
   "metadata": {},
   "source": [
    "## Récupérer la distribution des ports de départ pour les navires partis à Marseille en 1789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee3c4a1-a4e9-47da-a91a-a6c6db7a74ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "departures = Counter()\n",
    "with open('../data/navigo_all_flows.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if \\\n",
    "                row['destination_fr'] == 'Marseille' \\\n",
    "            and row['indate_fixed'].split('-')[0] == '1789' \\\n",
    "            :\n",
    "            departure = row['departure_fr']\n",
    "            departures.update({departure: 1})\n",
    "            \n",
    "departures_as_array = [{\"departure\": departure, \"count\": count} for departure, count in departures.items()]\n",
    "for p in sorted(departures_as_array, key=lambda d : -d['count']):\n",
    "    print(p['departure'] + ' : ' + str(p['count']) + ' voyages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c233df4-df3f-474c-9c60-bf0f6ddb548a",
   "metadata": {},
   "source": [
    "## Récupérer la liste des tonnages réalisée par Pierre Niccolo (valable pour tout autre csv en ligne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c1f54a-b00b-4f7d-913f-22a3ace63f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "def get_online_csv(url):\n",
    "  results = []\n",
    "  with requests.Session() as s:\n",
    "      download = s.get(url)\n",
    "      decoded_content = download.content.decode('utf-8')\n",
    "      reader = csv.DictReader(decoded_content.splitlines(), delimiter=',')\n",
    "      for row in reader:\n",
    "        results.append(dict(row))\n",
    "  return results\n",
    "\n",
    "TONNAGE_SPREADSHEET_URL = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTYdeIwpzaVpY_KS91cXiHxb309iYBS4JN_1_hW-_oyeysuwcIpC2VJ5fWeZJl4tA/pub?output=csv'\n",
    "\n",
    "tonnage_data = get_online_csv(TONNAGE_SPREADSHEET_URL)\n",
    "print(tonnage_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c67808-1c93-4e9d-b18c-d0487c336e5c",
   "metadata": {},
   "source": [
    "## Récupérer la distribution des ports de départ pour les navires partis à Marseille en 1789, par tonnage cumulé selon les estimations de Pierre Niccolò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a927f6-4981-413b-a31d-0e58f4ec7ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "from collections import Counter\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# 1. get online csv data\n",
    "def get_online_csv(url):\n",
    "  results = []\n",
    "  with requests.Session() as s:\n",
    "      download = s.get(url)\n",
    "      decoded_content = download.content.decode('utf-8')\n",
    "      reader = csv.DictReader(decoded_content.splitlines(), delimiter=',')\n",
    "      for row in reader:\n",
    "        results.append(dict(row))\n",
    "  return results\n",
    "\n",
    "TONNAGE_SPREADSHEET_URL = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTYdeIwpzaVpY_KS91cXiHxb309iYBS4JN_1_hW-_oyeysuwcIpC2VJ5fWeZJl4tA/pub?output=csv'\n",
    "\n",
    "tonnage_data = get_online_csv(TONNAGE_SPREADSHEET_URL)\n",
    "\n",
    "# 2. build a shipclass->tx dict\n",
    "tonnage_estimates = {}\n",
    "for l in tonnage_data:\n",
    "    estimation = l['tonnage_estime_en_tx'] or 0\n",
    "    if l['tonnage_estime_en_tx'] == 'No data':\n",
    "        estimation = 0\n",
    "    else :\n",
    "        estimation = int(estimation)\n",
    "    \n",
    "    ship_class = l['ship_class']\n",
    "    \n",
    "    tonnage_estimates[ship_class] = estimation\n",
    "\n",
    "# 1. count departures aggregating by tonnage\n",
    "departures = Counter()\n",
    "with open('../data/navigo_all_flows.csv', newline='') as csvfile:\n",
    "    reader = DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        # filter relevant flows\n",
    "        if \\\n",
    "                row['destination_fr'] == 'Marseille' \\\n",
    "            and row['indate_fixed'].split('-')[0] == '1789' \\\n",
    "            :\n",
    "            departure = row['departure_fr']\n",
    "            ship_class = row['ship_class_standardized']\n",
    "            tonnage = 0\n",
    "            # check ship_class is covered by our estimates\n",
    "            if ship_class in tonnage_estimates:\n",
    "                tonnage = tonnage_estimates[ship_class]\n",
    "            elif ship_class != '':\n",
    "                # note : should we use the built-in tonnage instead of doing nothing here?\n",
    "                print('not in estimates : ' + ship_class)\n",
    "                \n",
    "            # update counter\n",
    "            departures.update({departure: tonnage})\n",
    "            \n",
    "departures_as_array = [{\"departure\": departure, \"count\": count} for departure, count in departures.items()]\n",
    "for p in sorted(departures_as_array, key=lambda d : -d['count']):\n",
    "    print(p['departure'] + ' : ' + str(p['count']) + ' tonneaux cumulés')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
